{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wordcount_in_Haddoop.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHBEub5D4kJcQ1Iz/oSonp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratikshas8080/hadoop-platform-and-application-framework/blob/master/wordcount_in_Haddoop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcgCNDx8AotF"
      },
      "source": [
        "#wordcount assignment in Hadoop course"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85d9fy2X10PE"
      },
      "source": [
        "#!/usr/bin/env python   \n",
        "#the above just indicates to use python to intepret this file\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "#This mapper code will input a line of text and output <word, 1>\n",
        "# \n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "import sys             #a python module with system functions for this OS\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "#  this 'for loop' will set 'line' to an input line from system \n",
        "#    standard input file\n",
        "# ------------------------------------------------------------\n",
        "for line in sys.stdin:  \n",
        "\n",
        "#-----------------------------------\n",
        "#sys.stdin call 'sys' to read a line from standard input, \n",
        "# note that 'line' is a string object, ie variable, and it has methods that you can apply to it,\n",
        "# as in the next line\n",
        "# ---------------------------------\n",
        "    line = line.strip()  #strip is a method, ie function, associated\n",
        "                         #  with string variable, it will strip \n",
        "                         #   the carriage return (by default)\n",
        "    keys = line.split()  #split line at blanks (by default), \n",
        "                         #   and return a list of keys\n",
        "    for key in keys:     #a for loop through the list of keys\n",
        "        value = 1        \n",
        "        print('{0}\\t{1}'.format(key, value) ) #the {} is replaced by 0th,1st items in format list\n",
        "                            #also, note that the Hadoop default is 'tab' separates key from the value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcTb7VdZ19xM"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "#This reducer code will input a line of text and \n",
        "#    output <word, total-count>\n",
        "# ---------------------------------------------------------------\n",
        "import sys\n",
        "\n",
        "last_key      = None              #initialize these variables\n",
        "running_total = 0\n",
        "\n",
        "# -----------------------------------\n",
        "# Loop thru file\n",
        "#  --------------------------------\n",
        "for input_line in sys.stdin:\n",
        "    input_line = input_line.strip()\n",
        "\n",
        "    # --------------------------------\n",
        "    # Get Next Word    # --------------------------------\n",
        "    this_key, value = input_line.split(\"\\t\", 1)  #the Hadoop default is tab separates key value\n",
        "                          #the split command returns a list of strings, in this case into 2 variables\n",
        "    value = int(value)           #int() will convert a string to integer (this program does no error checking)\n",
        " \n",
        "    # ---------------------------------\n",
        "    # Key Check part\n",
        "    #    if this current key is same \n",
        "    #          as the last one Consolidate\n",
        "    #    otherwise  Emit\n",
        "    # ---------------------------------\n",
        "    if last_key == this_key:     #check if key has changed ('==' is                                   #      logical equalilty check\n",
        "        running_total += value   # add value to running total\n",
        "\n",
        "    else:\n",
        "        if last_key:             #if this key that was just read in\n",
        "                                 #   is different, and the previous \n",
        "                                 #   (ie last) key is not empy,\n",
        "                                 #   then output \n",
        "                                 #   the previous <key running-count>\n",
        "            print( \"{0}\\t{1}\".format(last_key, running_total) )\n",
        "                                 # hadoop expects tab(ie '\\t') \n",
        "                                 #    separation\n",
        "        running_total = value    #reset values\n",
        "        last_key = this_key\n",
        "\n",
        "if last_key == this_key:\n",
        "    print( \"{0}\\t{1}\".format(last_key, running_total))"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}